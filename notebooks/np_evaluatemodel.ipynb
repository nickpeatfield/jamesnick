{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noon/PycharmProjects/jamesnick/venv/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "def make_acc_dataset(model, dataset):\n",
    "  n = len(dataset)\n",
    "  for i in range(n):\n",
    "      x, y = dataset[i][0], dataset[i][1]\n",
    "      with torch.no_grad():\n",
    "          pred = model(x)\n",
    "      if (not(pred[0].argmax(0) - y)):\n",
    "          dataset.targets[i] = 1\n",
    "      else:\n",
    "          dataset.targets[i] = 0\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetworkClass(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n",
      "NeuralNetworkPred(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=2, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# As we save\n",
    "device = \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "# Define model\n",
    "class NeuralNetworkClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetworkClass, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x).to(device)\n",
    "        return logits\n",
    "\n",
    "class_model = NeuralNetworkClass().to(device)\n",
    "print(class_model)\n",
    "\n",
    "class NeuralNetworkPred(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetworkPred, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x).to(device)\n",
    "        return logits\n",
    "pred_model = NeuralNetworkPred().to(device)\n",
    "print(pred_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "path = os.getcwd()\n",
    "model = NeuralNetworkPred()\n",
    "model.load_state_dict(torch.load(path + os.path.sep + '1' + '_pred_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make a function that loads the models into a python list\n",
    "def load_acc_models(path,n_of_models):\n",
    "    model_list = []\n",
    "    for i in range(n_of_models):\n",
    "        new_model = NeuralNetworkPred()\n",
    "        new_model.load_state_dict(torch.load(path + os.path.sep + str(i + 1) + '_pred_model.pth'))\n",
    "        new_model.eval()\n",
    "        model_list.append(new_model)\n",
    "        del new_model\n",
    "    return model_list\n",
    "        \n",
    "# Lets make a function that loads the models into a python list\n",
    "def load_class_models(path,n_of_models):\n",
    "    model_list = []\n",
    "    for i in range(n_of_models):\n",
    "        new_model = NeuralNetworkClass()\n",
    "        new_model.load_state_dict(torch.load(path + os.path.sep + str(i + 1) + '_allclass_model.pth'))\n",
    "        new_model.eval()\n",
    "        model_list.append(new_model)\n",
    "        del new_model\n",
    "    return model_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "path = os.getcwd()\n",
    "n_of_models = 10\n",
    "\n",
    "list_of_acc_model = load_acc_models(path,n_of_models)\n",
    "list_of_class_model = load_class_models(path,n_of_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in one data image and then evaluate it on the best model for acc..\n",
    "\n",
    "x = test_data[0][0]\n",
    "\n",
    "def get_acc_model_predict_list(x,model_list):\n",
    "    predict_list = np.zeros(len(model_list))\n",
    "    for i, model in enumerate(model_list):\n",
    "        with torch.no_grad():\n",
    "            pred = model(x)\n",
    "        predict_list[i] = pred[0,1].numpy()\n",
    "    return predict_list\n",
    "\n",
    "pred_list = get_acc_model_predict_list(x,list_of_acc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "# Test an small chuck on the predicted vs. actual\n",
    "\n",
    "x = test_data[0][0]\n",
    "y = test_data[0][1]\n",
    "def get_class_model_predict_list(x,y,model_list):\n",
    "    predict_list = []\n",
    "    for model in model_list:\n",
    "        with torch.no_grad():\n",
    "            pred = model(x)\n",
    "        print(pred[0].argmax(0))\n",
    "        predict_list.append(pred)\n",
    "    return predict_list\n",
    "\n",
    "class_list = get_class_model_predict_list(x,y,list_of_class_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class = tensor([9]), actual = 9\n",
      "Predicted class = tensor([2]), actual = 2\n",
      "Predicted class = tensor([1]), actual = 1\n",
      "Predicted class = tensor([1]), actual = 1\n",
      "Predicted class = tensor([6]), actual = 6\n",
      "Predicted class = tensor([1]), actual = 1\n",
      "Predicted class = tensor([4]), actual = 4\n",
      "Predicted class = tensor([4]), actual = 6\n",
      "Predicted class = tensor([1]), actual = 5\n",
      "Predicted class = tensor([1]), actual = 7\n",
      "Predicted class = tensor([2]), actual = 4\n",
      "Predicted class = tensor([5]), actual = 5\n",
      "Predicted class = tensor([5]), actual = 7\n",
      "Predicted class = tensor([1]), actual = 3\n",
      "Predicted class = tensor([4]), actual = 4\n",
      "Predicted class = tensor([1]), actual = 1\n",
      "Predicted class = tensor([2]), actual = 2\n",
      "Predicted class = tensor([2]), actual = 4\n",
      "Predicted class = tensor([8]), actual = 8\n",
      "Predicted class = tensor([0]), actual = 0\n",
      "Predicted class = tensor([0]), actual = 2\n",
      "Accuracy of the network on the 10000 test images: 0 %\n"
     ]
    }
   ],
   "source": [
    "# Lets test the final model.\n",
    "\n",
    "def evaluate_hydra(data,acc_model_lists,class_model_list):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, d in enumerate(data):\n",
    "        predict_list = get_acc_model_predict_list(d[0],acc_model_lists)\n",
    "        with torch.no_grad():\n",
    "            pred = class_model_list[predict_list.argmax()](d[0])\n",
    "            _, predicted = torch.max(pred.data, 1)\n",
    "            label = d[1]\n",
    "            print(f'Predicted class = {predicted}, actual = {label}')\n",
    "            correct += (predicted == d[1]).sum().item()\n",
    "        if i == 20:\n",
    "            break\n",
    "    return len(data), correct\n",
    "\n",
    "\n",
    "total, correct = evaluate_hydra(test_data,list_of_acc_model,list_of_class_model)\n",
    "\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}