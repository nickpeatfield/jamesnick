{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noon/PycharmProjects/jamesnick/venv/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# LETS JUST USE THE PYTORCH TUTORIAL DATASET i.e. FASHIONMNIST\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "def make_acc_dataset(model, dataset):\n",
    "  n = len(dataset)\n",
    "  for i in range(n):\n",
    "      x, y = dataset[i][0], dataset[i][1]\n",
    "      with torch.no_grad():\n",
    "          pred = model(x)\n",
    "      if (not(pred[0].argmax(0) - y)):\n",
    "          dataset.targets[i] = 1\n",
    "      else:\n",
    "          dataset.targets[i] = 0\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetworkClass(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n",
      "NeuralNetworkPred(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=2, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "# Define model\n",
    "class NeuralNetworkClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetworkClass, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x).to(device)\n",
    "        return logits\n",
    "\n",
    "class_model = NeuralNetworkClass().to(device)\n",
    "print(class_model)\n",
    "\n",
    "class NeuralNetworkPred(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetworkPred, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x).to(device)\n",
    "        return logits\n",
    "\n",
    "\n",
    "pred_model = NeuralNetworkPred().to(device)\n",
    "print(pred_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn_class = nn.CrossEntropyLoss()\n",
    "optimizer_class = torch.optim.SGD(class_model.parameters(), lr=1e-3)\n",
    "loss_fn_pred = nn.CrossEntropyLoss()\n",
    "optimizer_pred = torch.optim.SGD(pred_model.parameters(), lr=1e-3)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, min_loss):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    if test_loss < min_loss:\n",
    "        print(f\"Early Stopping: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "        return 1\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return 0\n",
    "\n",
    "def weight_reset(m):\n",
    "    reset_parameters = getattr(m, \"reset_parameters\", None)\n",
    "    if callable(reset_parameters):\n",
    "        m.reset_parameters()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Gen Time \n",
      "\n",
      "Epoch 1 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 36.5%, Avg loss: 2.205116 \n",
      "\n",
      "Epoch 2 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 49.1%, Avg loss: 2.024893 \n",
      "\n",
      "Epoch 3 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 58.9%, Avg loss: 1.724732 \n",
      "\n",
      "Epoch 4 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 1.437120 \n",
      "\n",
      "Epoch 5 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 1.195258 \n",
      "\n",
      "Epoch 6 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 1.042225 \n",
      "\n",
      "Epoch 7 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 65.5%, Avg loss: 0.947646 \n",
      "\n",
      "Epoch 8 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 0.885190 \n",
      "\n",
      "Epoch 9 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 67.6%, Avg loss: 0.840646 \n",
      "\n",
      "Epoch 10 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 0.806451 \n",
      "\n",
      "Epoch 11 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 0.778610 \n",
      "\n",
      "Epoch 12 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.754849 \n",
      "\n",
      "Epoch 13 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.733869 \n",
      "\n",
      "Epoch 14 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.714944 \n",
      "\n",
      "Epoch 15 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.697643 \n",
      "\n",
      "Epoch 16 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.681716 \n",
      "\n",
      "Epoch 17 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.667014 \n",
      "\n",
      "Epoch 18 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.653452 \n",
      "\n",
      "Epoch 19 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.640939 \n",
      "\n",
      "Epoch 20 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.629410 \n",
      "\n",
      "Epoch 21 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.618801 \n",
      "\n",
      "Epoch 22 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.609013 \n",
      "\n",
      "Epoch 23 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.600016 \n",
      "\n",
      "Epoch 24 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.591726 \n",
      "\n",
      "Epoch 25 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.584078 \n",
      "\n",
      "Epoch 26 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.576988 \n",
      "\n",
      "Epoch 27 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.570431 \n",
      "\n",
      "Epoch 28 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.564347 \n",
      "\n",
      "Epoch 29 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.558690 \n",
      "\n",
      "Epoch 30 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.553421 \n",
      "\n",
      "Epoch 31 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.548498 \n",
      "\n",
      "Epoch 32 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.543890 \n",
      "\n",
      "Epoch 33 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.539572 \n",
      "\n",
      "Epoch 34 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.535519 \n",
      "\n",
      "Epoch 35 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.531719 \n",
      "\n",
      "Epoch 36 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.528140 \n",
      "\n",
      "Epoch 37 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.524767 \n",
      "\n",
      "Epoch 38 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.521576 \n",
      "\n",
      "Epoch 39 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.518549 \n",
      "\n",
      "Epoch 40 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.515676 \n",
      "\n",
      "Epoch 41 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.512935 \n",
      "\n",
      "Epoch 42 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.510323 \n",
      "\n",
      "Epoch 43 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.507824 \n",
      "\n",
      "Epoch 44 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.505436 \n",
      "\n",
      "Epoch 45 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.503151 \n",
      "\n",
      "Epoch 46 of gen 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.500956 \n",
      "\n",
      "Epoch 47 of gen 1\n",
      "-------------------------------\n",
      "Early Stopping: \n",
      " Accuracy: 82.4%, Avg loss: 0.498850 \n",
      "\n",
      "Saved PyTorch Model State to 1_allclass_model.pth\n",
      "Predicting 1\n",
      "-------------------------------\n",
      "Epoch 1 of gen 1 pred class \n",
      "-------------------------------\n",
      "Early Stopping: \n",
      " Accuracy: 82.4%, Avg loss: 0.487448 \n",
      "\n",
      "Saved PyTorch Model State to 1_pred_model.pth\n",
      "New Gen Time \n",
      "\n",
      "Epoch 1 of gen 2\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.581581 \n",
      "\n",
      "Epoch 2 of gen 2\n",
      "-------------------------------\n",
      "Early Stopping: \n",
      " Accuracy: 82.4%, Avg loss: 0.497499 \n",
      "\n",
      "Saved PyTorch Model State to 2_allclass_model.pth\n",
      "Predicting 2\n",
      "-------------------------------\n",
      "Epoch 1 of gen 2 pred class \n",
      "-------------------------------\n",
      "Early Stopping: \n",
      " Accuracy: 82.4%, Avg loss: 0.487448 \n",
      "\n",
      "Saved PyTorch Model State to 2_pred_model.pth\n",
      "New Gen Time \n",
      "\n",
      "Epoch 1 of gen 3\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.581581 \n",
      "\n",
      "Epoch 2 of gen 3\n",
      "-------------------------------\n",
      "Early Stopping: \n",
      " Accuracy: 82.4%, Avg loss: 0.497499 \n",
      "\n",
      "Saved PyTorch Model State to 3_allclass_model.pth\n",
      "Predicting 3\n",
      "-------------------------------\n",
      "Epoch 1 of gen 3 pred class \n",
      "-------------------------------\n",
      "Early Stopping: \n",
      " Accuracy: 82.4%, Avg loss: 0.487448 \n",
      "\n",
      "Saved PyTorch Model State to 3_pred_model.pth\n",
      "New Gen Time \n",
      "\n",
      "Epoch 1 of gen 4\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.581581 \n",
      "\n",
      "Epoch 2 of gen 4\n",
      "-------------------------------\n",
      "Early Stopping: \n",
      " Accuracy: 82.4%, Avg loss: 0.497499 \n",
      "\n",
      "Saved PyTorch Model State to 4_allclass_model.pth\n",
      "Predicting 4\n",
      "-------------------------------\n",
      "Epoch 1 of gen 4 pred class \n",
      "-------------------------------\n",
      "Early Stopping: \n",
      " Accuracy: 82.4%, Avg loss: 0.487448 \n",
      "\n",
      "Saved PyTorch Model State to 4_pred_model.pth\n",
      "New Gen Time \n",
      "\n",
      "Epoch 1 of gen 5\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.581581 \n",
      "\n",
      "Epoch 2 of gen 5\n",
      "-------------------------------\n",
      "Early Stopping: \n",
      " Accuracy: 82.4%, Avg loss: 0.497499 \n",
      "\n",
      "Saved PyTorch Model State to 5_allclass_model.pth\n",
      "Predicting 5\n",
      "-------------------------------\n",
      "Epoch 1 of gen 5 pred class \n",
      "-------------------------------\n",
      "Early Stopping: \n",
      " Accuracy: 82.4%, Avg loss: 0.487448 \n",
      "\n",
      "Saved PyTorch Model State to 5_pred_model.pth\n",
      "New Gen Time \n",
      "\n",
      "Epoch 1 of gen 6\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.581581 \n",
      "\n",
      "Epoch 2 of gen 6\n",
      "-------------------------------\n",
      "Early Stopping: \n",
      " Accuracy: 82.4%, Avg loss: 0.497499 \n",
      "\n",
      "Saved PyTorch Model State to 6_allclass_model.pth\n",
      "Predicting 6\n",
      "-------------------------------\n",
      "Epoch 1 of gen 6 pred class \n",
      "-------------------------------\n",
      "Early Stopping: \n",
      " Accuracy: 82.4%, Avg loss: 0.487448 \n",
      "\n",
      "Saved PyTorch Model State to 6_pred_model.pth\n",
      "New Gen Time \n",
      "\n",
      "Epoch 1 of gen 7\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.581581 \n",
      "\n",
      "Epoch 2 of gen 7\n",
      "-------------------------------\n",
      "Early Stopping: \n",
      " Accuracy: 82.4%, Avg loss: 0.497499 \n",
      "\n",
      "Saved PyTorch Model State to 7_allclass_model.pth\n",
      "Predicting 7\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.save(class_model.state_dict(), f\"blankallclass_model.pth\")\n",
    "torch.save(pred_model.state_dict(), f\"blankpred_model.pth\")\n",
    "\n",
    "epochs = 50\n",
    "model_gens = 20\n",
    "for g in range(model_gens):\n",
    "    # Reset all the models\n",
    "    # Full 10 class\n",
    "    print(f\"New Gen Time \\n\")\n",
    "    class_model = NeuralNetworkClass()\n",
    "    class_model.load_state_dict(torch.load(\"blankallclass_model.pth\"))\n",
    "    loss_fn_class = nn.CrossEntropyLoss()\n",
    "    optimizer_class = torch.optim.SGD(class_model.parameters(), lr=1e-3)\n",
    "    # Just predict\n",
    "    pred_model = NeuralNetworkPred()\n",
    "    pred_model.load_state_dict(torch.load(\"blankpred_model.pth\"))\n",
    "    loss_fn_pred = nn.CrossEntropyLoss()\n",
    "    optimizer_pred = torch.optim.SGD(pred_model.parameters(), lr=1e-3)\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1} of gen {g+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, class_model, loss_fn_class, optimizer_class)\n",
    "        early_stopping = test(test_dataloader, class_model, loss_fn_class, 0.5)\n",
    "        if early_stopping == 1 or t == epochs:\n",
    "            torch.save(class_model.state_dict(), f\"{g+1}_allclass_model.pth\")\n",
    "            print(f\"Saved PyTorch Model State to {g+1}_allclass_model.pth\")\n",
    "            print(f\"Predicting {g+1}\\n-------------------------------\")\n",
    "            pred_train_dataset = make_acc_dataset(class_model,training_data)\n",
    "            pred_test_dataset = make_acc_dataset(class_model,test_data)\n",
    "            pred_train_dataloader = DataLoader(pred_train_dataset, batch_size=batch_size)\n",
    "            pred_test_dataloader = DataLoader(pred_test_dataset, batch_size=batch_size)\n",
    "            for p in range(epochs):\n",
    "                print(f\"Epoch {p+1} of gen {g+1} pred class \\n-------------------------------\")\n",
    "                train(pred_train_dataloader, pred_model, loss_fn_pred, optimizer_pred)\n",
    "                early_stopping = test(pred_test_dataloader, pred_model, loss_fn_pred, 0.5)\n",
    "                if early_stopping == 1 or p == epochs:\n",
    "                    torch.save(pred_model.state_dict(), f\"{g+1}_pred_model.pth\")\n",
    "                    print(f\"Saved PyTorch Model State to {g+1}_pred_model.pth\")\n",
    "                    break\n",
    "            break\n",
    "\n",
    "\n",
    "print(\"Done!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}