{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11.6%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "47.7%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "84.4%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68.7%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.708486  [    0/60000]\n",
      "loss: 0.809879  [ 6400/60000]\n",
      "loss: 0.559385  [12800/60000]\n",
      "loss: 0.939757  [19200/60000]\n",
      "loss: 0.822234  [25600/60000]\n",
      "loss: 0.782956  [32000/60000]\n",
      "loss: 0.996635  [38400/60000]\n",
      "loss: 0.884460  [44800/60000]\n",
      "loss: 0.953347  [51200/60000]\n",
      "loss: 1.026872  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.820157 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.693851  [    0/60000]\n",
      "loss: 0.796479  [ 6400/60000]\n",
      "loss: 0.549466  [12800/60000]\n",
      "loss: 0.927647  [19200/60000]\n",
      "loss: 0.811464  [25600/60000]\n",
      "loss: 0.774269  [32000/60000]\n",
      "loss: 0.983909  [38400/60000]\n",
      "loss: 0.882596  [44800/60000]\n",
      "loss: 0.945661  [51200/60000]\n",
      "loss: 1.013307  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.810029 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.680335  [    0/60000]\n",
      "loss: 0.784503  [ 6400/60000]\n",
      "loss: 0.540587  [12800/60000]\n",
      "loss: 0.916568  [19200/60000]\n",
      "loss: 0.801504  [25600/60000]\n",
      "loss: 0.766218  [32000/60000]\n",
      "loss: 0.972775  [38400/60000]\n",
      "loss: 0.881281  [44800/60000]\n",
      "loss: 0.938792  [51200/60000]\n",
      "loss: 1.000921  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 0.800870 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.667954  [    0/60000]\n",
      "loss: 0.773716  [ 6400/60000]\n",
      "loss: 0.532574  [12800/60000]\n",
      "loss: 0.906343  [19200/60000]\n",
      "loss: 0.792399  [25600/60000]\n",
      "loss: 0.758592  [32000/60000]\n",
      "loss: 0.962889  [38400/60000]\n",
      "loss: 0.880406  [44800/60000]\n",
      "loss: 0.932611  [51200/60000]\n",
      "loss: 0.989798  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 0.792570 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.656640  [    0/60000]\n",
      "loss: 0.763906  [ 6400/60000]\n",
      "loss: 0.525318  [12800/60000]\n",
      "loss: 0.896794  [19200/60000]\n",
      "loss: 0.783704  [25600/60000]\n",
      "loss: 0.751439  [32000/60000]\n",
      "loss: 0.954173  [38400/60000]\n",
      "loss: 0.879899  [44800/60000]\n",
      "loss: 0.927130  [51200/60000]\n",
      "loss: 0.979710  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.785029 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.646217  [    0/60000]\n",
      "loss: 0.755024  [ 6400/60000]\n",
      "loss: 0.518811  [12800/60000]\n",
      "loss: 0.887775  [19200/60000]\n",
      "loss: 0.775422  [25600/60000]\n",
      "loss: 0.744672  [32000/60000]\n",
      "loss: 0.946472  [38400/60000]\n",
      "loss: 0.879566  [44800/60000]\n",
      "loss: 0.922139  [51200/60000]\n",
      "loss: 0.970598  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 0.778150 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.636357  [    0/60000]\n",
      "loss: 0.746924  [ 6400/60000]\n",
      "loss: 0.512911  [12800/60000]\n",
      "loss: 0.879453  [19200/60000]\n",
      "loss: 0.767656  [25600/60000]\n",
      "loss: 0.738216  [32000/60000]\n",
      "loss: 0.939685  [38400/60000]\n",
      "loss: 0.879328  [44800/60000]\n",
      "loss: 0.917650  [51200/60000]\n",
      "loss: 0.961931  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 0.771856 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.627145  [    0/60000]\n",
      "loss: 0.739423  [ 6400/60000]\n",
      "loss: 0.507414  [12800/60000]\n",
      "loss: 0.871837  [19200/60000]\n",
      "loss: 0.760226  [25600/60000]\n",
      "loss: 0.732009  [32000/60000]\n",
      "loss: 0.933579  [38400/60000]\n",
      "loss: 0.879295  [44800/60000]\n",
      "loss: 0.913764  [51200/60000]\n",
      "loss: 0.953839  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.766104 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.618500  [    0/60000]\n",
      "loss: 0.732573  [ 6400/60000]\n",
      "loss: 0.502279  [12800/60000]\n",
      "loss: 0.864646  [19200/60000]\n",
      "loss: 0.753200  [25600/60000]\n",
      "loss: 0.725908  [32000/60000]\n",
      "loss: 0.928076  [38400/60000]\n",
      "loss: 0.879299  [44800/60000]\n",
      "loss: 0.910277  [51200/60000]\n",
      "loss: 0.946362  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.760818 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.610405  [    0/60000]\n",
      "loss: 0.726411  [ 6400/60000]\n",
      "loss: 0.497650  [12800/60000]\n",
      "loss: 0.857722  [19200/60000]\n",
      "loss: 0.746547  [25600/60000]\n",
      "loss: 0.719933  [32000/60000]\n",
      "loss: 0.923144  [38400/60000]\n",
      "loss: 0.879286  [44800/60000]\n",
      "loss: 0.907267  [51200/60000]\n",
      "loss: 0.939305  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.755940 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.602822  [    0/60000]\n",
      "loss: 0.720839  [ 6400/60000]\n",
      "loss: 0.493338  [12800/60000]\n",
      "loss: 0.851349  [19200/60000]\n",
      "loss: 0.740051  [25600/60000]\n",
      "loss: 0.714076  [32000/60000]\n",
      "loss: 0.918541  [38400/60000]\n",
      "loss: 0.879074  [44800/60000]\n",
      "loss: 0.904552  [51200/60000]\n",
      "loss: 0.932724  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.751416 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.595576  [    0/60000]\n",
      "loss: 0.715712  [ 6400/60000]\n",
      "loss: 0.489315  [12800/60000]\n",
      "loss: 0.845314  [19200/60000]\n",
      "loss: 0.733855  [25600/60000]\n",
      "loss: 0.708514  [32000/60000]\n",
      "loss: 0.914282  [38400/60000]\n",
      "loss: 0.878717  [44800/60000]\n",
      "loss: 0.901843  [51200/60000]\n",
      "loss: 0.926649  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 0.747214 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.588705  [    0/60000]\n",
      "loss: 0.710934  [ 6400/60000]\n",
      "loss: 0.485628  [12800/60000]\n",
      "loss: 0.839716  [19200/60000]\n",
      "loss: 0.727909  [25600/60000]\n",
      "loss: 0.703153  [32000/60000]\n",
      "loss: 0.910394  [38400/60000]\n",
      "loss: 0.878391  [44800/60000]\n",
      "loss: 0.899342  [51200/60000]\n",
      "loss: 0.921052  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.743314 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.582191  [    0/60000]\n",
      "loss: 0.706612  [ 6400/60000]\n",
      "loss: 0.482203  [12800/60000]\n",
      "loss: 0.834305  [19200/60000]\n",
      "loss: 0.722198  [25600/60000]\n",
      "loss: 0.697903  [32000/60000]\n",
      "loss: 0.906723  [38400/60000]\n",
      "loss: 0.877984  [44800/60000]\n",
      "loss: 0.896815  [51200/60000]\n",
      "loss: 0.915759  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.739659 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.576021  [    0/60000]\n",
      "loss: 0.702741  [ 6400/60000]\n",
      "loss: 0.478907  [12800/60000]\n",
      "loss: 0.829128  [19200/60000]\n",
      "loss: 0.716842  [25600/60000]\n",
      "loss: 0.692794  [32000/60000]\n",
      "loss: 0.903258  [38400/60000]\n",
      "loss: 0.877392  [44800/60000]\n",
      "loss: 0.894284  [51200/60000]\n",
      "loss: 0.910870  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.736242 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.570119  [    0/60000]\n",
      "loss: 0.699078  [ 6400/60000]\n",
      "loss: 0.475777  [12800/60000]\n",
      "loss: 0.824269  [19200/60000]\n",
      "loss: 0.711630  [25600/60000]\n",
      "loss: 0.687832  [32000/60000]\n",
      "loss: 0.899943  [38400/60000]\n",
      "loss: 0.876598  [44800/60000]\n",
      "loss: 0.891908  [51200/60000]\n",
      "loss: 0.906354  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.733028 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.564452  [    0/60000]\n",
      "loss: 0.695718  [ 6400/60000]\n",
      "loss: 0.472836  [12800/60000]\n",
      "loss: 0.819657  [19200/60000]\n",
      "loss: 0.706580  [25600/60000]\n",
      "loss: 0.683067  [32000/60000]\n",
      "loss: 0.896811  [38400/60000]\n",
      "loss: 0.875574  [44800/60000]\n",
      "loss: 0.889542  [51200/60000]\n",
      "loss: 0.902057  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.729994 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.559109  [    0/60000]\n",
      "loss: 0.692829  [ 6400/60000]\n",
      "loss: 0.470008  [12800/60000]\n",
      "loss: 0.815274  [19200/60000]\n",
      "loss: 0.701666  [25600/60000]\n",
      "loss: 0.678387  [32000/60000]\n",
      "loss: 0.893807  [38400/60000]\n",
      "loss: 0.874402  [44800/60000]\n",
      "loss: 0.887267  [51200/60000]\n",
      "loss: 0.897869  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.727115 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.554023  [    0/60000]\n",
      "loss: 0.689988  [ 6400/60000]\n",
      "loss: 0.467308  [12800/60000]\n",
      "loss: 0.811083  [19200/60000]\n",
      "loss: 0.696987  [25600/60000]\n",
      "loss: 0.673973  [32000/60000]\n",
      "loss: 0.891002  [38400/60000]\n",
      "loss: 0.873192  [44800/60000]\n",
      "loss: 0.885024  [51200/60000]\n",
      "loss: 0.894088  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.724387 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.549107  [    0/60000]\n",
      "loss: 0.687253  [ 6400/60000]\n",
      "loss: 0.464768  [12800/60000]\n",
      "loss: 0.807138  [19200/60000]\n",
      "loss: 0.692526  [25600/60000]\n",
      "loss: 0.669726  [32000/60000]\n",
      "loss: 0.888370  [38400/60000]\n",
      "loss: 0.871782  [44800/60000]\n",
      "loss: 0.882819  [51200/60000]\n",
      "loss: 0.890650  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.721793 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.544367  [    0/60000]\n",
      "loss: 0.684634  [ 6400/60000]\n",
      "loss: 0.462305  [12800/60000]\n",
      "loss: 0.803402  [19200/60000]\n",
      "loss: 0.688290  [25600/60000]\n",
      "loss: 0.665603  [32000/60000]\n",
      "loss: 0.885850  [38400/60000]\n",
      "loss: 0.870317  [44800/60000]\n",
      "loss: 0.880620  [51200/60000]\n",
      "loss: 0.887316  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.719327 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.539718  [    0/60000]\n",
      "loss: 0.682111  [ 6400/60000]\n",
      "loss: 0.460023  [12800/60000]\n",
      "loss: 0.799686  [19200/60000]\n",
      "loss: 0.684328  [25600/60000]\n",
      "loss: 0.661732  [32000/60000]\n",
      "loss: 0.883546  [38400/60000]\n",
      "loss: 0.868862  [44800/60000]\n",
      "loss: 0.878454  [51200/60000]\n",
      "loss: 0.884195  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.716958 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.535254  [    0/60000]\n",
      "loss: 0.679773  [ 6400/60000]\n",
      "loss: 0.457743  [12800/60000]\n",
      "loss: 0.796122  [19200/60000]\n",
      "loss: 0.680299  [25600/60000]\n",
      "loss: 0.657975  [32000/60000]\n",
      "loss: 0.881401  [38400/60000]\n",
      "loss: 0.867231  [44800/60000]\n",
      "loss: 0.876405  [51200/60000]\n",
      "loss: 0.881294  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.714704 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.530953  [    0/60000]\n",
      "loss: 0.677548  [ 6400/60000]\n",
      "loss: 0.455616  [12800/60000]\n",
      "loss: 0.792768  [19200/60000]\n",
      "loss: 0.676584  [25600/60000]\n",
      "loss: 0.654401  [32000/60000]\n",
      "loss: 0.879279  [38400/60000]\n",
      "loss: 0.865640  [44800/60000]\n",
      "loss: 0.874417  [51200/60000]\n",
      "loss: 0.878292  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.712554 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.526797  [    0/60000]\n",
      "loss: 0.675447  [ 6400/60000]\n",
      "loss: 0.453662  [12800/60000]\n",
      "loss: 0.789611  [19200/60000]\n",
      "loss: 0.673150  [25600/60000]\n",
      "loss: 0.650998  [32000/60000]\n",
      "loss: 0.877232  [38400/60000]\n",
      "loss: 0.863969  [44800/60000]\n",
      "loss: 0.872490  [51200/60000]\n",
      "loss: 0.875693  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.710486 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.522765  [    0/60000]\n",
      "loss: 0.673338  [ 6400/60000]\n",
      "loss: 0.451790  [12800/60000]\n",
      "loss: 0.786529  [19200/60000]\n",
      "loss: 0.669745  [25600/60000]\n",
      "loss: 0.647804  [32000/60000]\n",
      "loss: 0.875211  [38400/60000]\n",
      "loss: 0.862160  [44800/60000]\n",
      "loss: 0.870609  [51200/60000]\n",
      "loss: 0.873283  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.708490 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.518935  [    0/60000]\n",
      "loss: 0.671185  [ 6400/60000]\n",
      "loss: 0.449962  [12800/60000]\n",
      "loss: 0.783603  [19200/60000]\n",
      "loss: 0.666427  [25600/60000]\n",
      "loss: 0.644697  [32000/60000]\n",
      "loss: 0.873291  [38400/60000]\n",
      "loss: 0.860291  [44800/60000]\n",
      "loss: 0.868748  [51200/60000]\n",
      "loss: 0.871009  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.706581 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.515093  [    0/60000]\n",
      "loss: 0.669186  [ 6400/60000]\n",
      "loss: 0.448253  [12800/60000]\n",
      "loss: 0.780799  [19200/60000]\n",
      "loss: 0.663243  [25600/60000]\n",
      "loss: 0.641687  [32000/60000]\n",
      "loss: 0.871344  [38400/60000]\n",
      "loss: 0.858423  [44800/60000]\n",
      "loss: 0.866838  [51200/60000]\n",
      "loss: 0.868827  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.704743 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.511377  [    0/60000]\n",
      "loss: 0.667233  [ 6400/60000]\n",
      "loss: 0.446646  [12800/60000]\n",
      "loss: 0.777961  [19200/60000]\n",
      "loss: 0.660148  [25600/60000]\n",
      "loss: 0.638751  [32000/60000]\n",
      "loss: 0.869422  [38400/60000]\n",
      "loss: 0.856452  [44800/60000]\n",
      "loss: 0.865030  [51200/60000]\n",
      "loss: 0.866768  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.702977 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.507779  [    0/60000]\n",
      "loss: 0.665368  [ 6400/60000]\n",
      "loss: 0.445132  [12800/60000]\n",
      "loss: 0.775306  [19200/60000]\n",
      "loss: 0.657265  [25600/60000]\n",
      "loss: 0.635952  [32000/60000]\n",
      "loss: 0.867608  [38400/60000]\n",
      "loss: 0.854406  [44800/60000]\n",
      "loss: 0.863130  [51200/60000]\n",
      "loss: 0.864812  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.701259 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.504295  [    0/60000]\n",
      "loss: 0.663547  [ 6400/60000]\n",
      "loss: 0.443658  [12800/60000]\n",
      "loss: 0.772786  [19200/60000]\n",
      "loss: 0.654400  [25600/60000]\n",
      "loss: 0.633155  [32000/60000]\n",
      "loss: 0.865794  [38400/60000]\n",
      "loss: 0.852299  [44800/60000]\n",
      "loss: 0.861204  [51200/60000]\n",
      "loss: 0.862972  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.699602 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.500941  [    0/60000]\n",
      "loss: 0.661713  [ 6400/60000]\n",
      "loss: 0.442244  [12800/60000]\n",
      "loss: 0.770347  [19200/60000]\n",
      "loss: 0.651637  [25600/60000]\n",
      "loss: 0.630603  [32000/60000]\n",
      "loss: 0.863999  [38400/60000]\n",
      "loss: 0.850158  [44800/60000]\n",
      "loss: 0.859291  [51200/60000]\n",
      "loss: 0.861218  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.698002 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.497684  [    0/60000]\n",
      "loss: 0.659878  [ 6400/60000]\n",
      "loss: 0.440972  [12800/60000]\n",
      "loss: 0.767962  [19200/60000]\n",
      "loss: 0.649003  [25600/60000]\n",
      "loss: 0.628147  [32000/60000]\n",
      "loss: 0.862229  [38400/60000]\n",
      "loss: 0.847941  [44800/60000]\n",
      "loss: 0.857368  [51200/60000]\n",
      "loss: 0.859556  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.696442 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.494575  [    0/60000]\n",
      "loss: 0.658026  [ 6400/60000]\n",
      "loss: 0.439769  [12800/60000]\n",
      "loss: 0.765725  [19200/60000]\n",
      "loss: 0.646359  [25600/60000]\n",
      "loss: 0.625812  [32000/60000]\n",
      "loss: 0.860474  [38400/60000]\n",
      "loss: 0.845835  [44800/60000]\n",
      "loss: 0.855466  [51200/60000]\n",
      "loss: 0.857957  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.694933 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.491571  [    0/60000]\n",
      "loss: 0.656239  [ 6400/60000]\n",
      "loss: 0.438760  [12800/60000]\n",
      "loss: 0.763574  [19200/60000]\n",
      "loss: 0.643768  [25600/60000]\n",
      "loss: 0.623566  [32000/60000]\n",
      "loss: 0.858756  [38400/60000]\n",
      "loss: 0.843679  [44800/60000]\n",
      "loss: 0.853463  [51200/60000]\n",
      "loss: 0.856434  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.693475 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.488713  [    0/60000]\n",
      "loss: 0.654621  [ 6400/60000]\n",
      "loss: 0.437730  [12800/60000]\n",
      "loss: 0.761478  [19200/60000]\n",
      "loss: 0.641193  [25600/60000]\n",
      "loss: 0.621383  [32000/60000]\n",
      "loss: 0.857084  [38400/60000]\n",
      "loss: 0.841511  [44800/60000]\n",
      "loss: 0.851577  [51200/60000]\n",
      "loss: 0.854989  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.692058 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.485953  [    0/60000]\n",
      "loss: 0.652989  [ 6400/60000]\n",
      "loss: 0.436656  [12800/60000]\n",
      "loss: 0.759447  [19200/60000]\n",
      "loss: 0.638705  [25600/60000]\n",
      "loss: 0.619269  [32000/60000]\n",
      "loss: 0.855451  [38400/60000]\n",
      "loss: 0.839322  [44800/60000]\n",
      "loss: 0.849671  [51200/60000]\n",
      "loss: 0.853625  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.690684 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.483268  [    0/60000]\n",
      "loss: 0.651422  [ 6400/60000]\n",
      "loss: 0.435664  [12800/60000]\n",
      "loss: 0.757496  [19200/60000]\n",
      "loss: 0.636250  [25600/60000]\n",
      "loss: 0.617240  [32000/60000]\n",
      "loss: 0.853798  [38400/60000]\n",
      "loss: 0.837080  [44800/60000]\n",
      "loss: 0.847645  [51200/60000]\n",
      "loss: 0.852370  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.689344 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.480719  [    0/60000]\n",
      "loss: 0.649801  [ 6400/60000]\n",
      "loss: 0.434696  [12800/60000]\n",
      "loss: 0.755601  [19200/60000]\n",
      "loss: 0.633905  [25600/60000]\n",
      "loss: 0.615259  [32000/60000]\n",
      "loss: 0.852290  [38400/60000]\n",
      "loss: 0.834928  [44800/60000]\n",
      "loss: 0.845819  [51200/60000]\n",
      "loss: 0.851150  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.688046 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.478244  [    0/60000]\n",
      "loss: 0.648203  [ 6400/60000]\n",
      "loss: 0.433740  [12800/60000]\n",
      "loss: 0.753715  [19200/60000]\n",
      "loss: 0.631517  [25600/60000]\n",
      "loss: 0.613346  [32000/60000]\n",
      "loss: 0.850755  [38400/60000]\n",
      "loss: 0.832817  [44800/60000]\n",
      "loss: 0.844059  [51200/60000]\n",
      "loss: 0.849954  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.686776 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.475836  [    0/60000]\n",
      "loss: 0.646593  [ 6400/60000]\n",
      "loss: 0.432786  [12800/60000]\n",
      "loss: 0.751970  [19200/60000]\n",
      "loss: 0.629145  [25600/60000]\n",
      "loss: 0.611497  [32000/60000]\n",
      "loss: 0.849266  [38400/60000]\n",
      "loss: 0.830782  [44800/60000]\n",
      "loss: 0.842271  [51200/60000]\n",
      "loss: 0.848748  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.685524 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.473581  [    0/60000]\n",
      "loss: 0.645064  [ 6400/60000]\n",
      "loss: 0.431853  [12800/60000]\n",
      "loss: 0.750160  [19200/60000]\n",
      "loss: 0.626916  [25600/60000]\n",
      "loss: 0.609701  [32000/60000]\n",
      "loss: 0.847780  [38400/60000]\n",
      "loss: 0.828705  [44800/60000]\n",
      "loss: 0.840524  [51200/60000]\n",
      "loss: 0.847657  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.684312 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.471288  [    0/60000]\n",
      "loss: 0.643577  [ 6400/60000]\n",
      "loss: 0.430991  [12800/60000]\n",
      "loss: 0.748415  [19200/60000]\n",
      "loss: 0.624750  [25600/60000]\n",
      "loss: 0.607954  [32000/60000]\n",
      "loss: 0.846379  [38400/60000]\n",
      "loss: 0.826596  [44800/60000]\n",
      "loss: 0.838725  [51200/60000]\n",
      "loss: 0.846661  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.683125 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.469092  [    0/60000]\n",
      "loss: 0.642091  [ 6400/60000]\n",
      "loss: 0.430183  [12800/60000]\n",
      "loss: 0.746789  [19200/60000]\n",
      "loss: 0.622655  [25600/60000]\n",
      "loss: 0.606264  [32000/60000]\n",
      "loss: 0.844979  [38400/60000]\n",
      "loss: 0.824489  [44800/60000]\n",
      "loss: 0.837019  [51200/60000]\n",
      "loss: 0.845711  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.681968 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.466950  [    0/60000]\n",
      "loss: 0.640607  [ 6400/60000]\n",
      "loss: 0.429342  [12800/60000]\n",
      "loss: 0.745096  [19200/60000]\n",
      "loss: 0.620652  [25600/60000]\n",
      "loss: 0.604605  [32000/60000]\n",
      "loss: 0.843628  [38400/60000]\n",
      "loss: 0.822413  [44800/60000]\n",
      "loss: 0.835348  [51200/60000]\n",
      "loss: 0.844777  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.680833 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.464856  [    0/60000]\n",
      "loss: 0.639135  [ 6400/60000]\n",
      "loss: 0.428532  [12800/60000]\n",
      "loss: 0.743491  [19200/60000]\n",
      "loss: 0.618715  [25600/60000]\n",
      "loss: 0.603010  [32000/60000]\n",
      "loss: 0.842292  [38400/60000]\n",
      "loss: 0.820350  [44800/60000]\n",
      "loss: 0.833646  [51200/60000]\n",
      "loss: 0.843899  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.679714 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.462838  [    0/60000]\n",
      "loss: 0.637675  [ 6400/60000]\n",
      "loss: 0.427759  [12800/60000]\n",
      "loss: 0.741948  [19200/60000]\n",
      "loss: 0.616714  [25600/60000]\n",
      "loss: 0.601422  [32000/60000]\n",
      "loss: 0.841008  [38400/60000]\n",
      "loss: 0.818352  [44800/60000]\n",
      "loss: 0.831987  [51200/60000]\n",
      "loss: 0.843028  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.678615 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.460895  [    0/60000]\n",
      "loss: 0.636248  [ 6400/60000]\n",
      "loss: 0.427010  [12800/60000]\n",
      "loss: 0.740399  [19200/60000]\n",
      "loss: 0.614902  [25600/60000]\n",
      "loss: 0.599893  [32000/60000]\n",
      "loss: 0.839725  [38400/60000]\n",
      "loss: 0.816368  [44800/60000]\n",
      "loss: 0.830225  [51200/60000]\n",
      "loss: 0.842228  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.677540 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.459007  [    0/60000]\n",
      "loss: 0.634816  [ 6400/60000]\n",
      "loss: 0.426314  [12800/60000]\n",
      "loss: 0.738867  [19200/60000]\n",
      "loss: 0.613033  [25600/60000]\n",
      "loss: 0.598388  [32000/60000]\n",
      "loss: 0.838456  [38400/60000]\n",
      "loss: 0.814398  [44800/60000]\n",
      "loss: 0.828561  [51200/60000]\n",
      "loss: 0.841428  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.676486 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.457192  [    0/60000]\n",
      "loss: 0.633399  [ 6400/60000]\n",
      "loss: 0.425560  [12800/60000]\n",
      "loss: 0.737412  [19200/60000]\n",
      "loss: 0.611194  [25600/60000]\n",
      "loss: 0.596936  [32000/60000]\n",
      "loss: 0.837153  [38400/60000]\n",
      "loss: 0.812427  [44800/60000]\n",
      "loss: 0.826941  [51200/60000]\n",
      "loss: 0.840638  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.675448 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.455436  [    0/60000]\n",
      "loss: 0.631999  [ 6400/60000]\n",
      "loss: 0.424878  [12800/60000]\n",
      "loss: 0.735952  [19200/60000]\n",
      "loss: 0.609476  [25600/60000]\n",
      "loss: 0.595473  [32000/60000]\n",
      "loss: 0.835909  [38400/60000]\n",
      "loss: 0.810458  [44800/60000]\n",
      "loss: 0.825337  [51200/60000]\n",
      "loss: 0.839898  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.674429 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.453733  [    0/60000]\n",
      "loss: 0.630646  [ 6400/60000]\n",
      "loss: 0.424234  [12800/60000]\n",
      "loss: 0.734481  [19200/60000]\n",
      "loss: 0.607786  [25600/60000]\n",
      "loss: 0.594047  [32000/60000]\n",
      "loss: 0.834675  [38400/60000]\n",
      "loss: 0.808546  [44800/60000]\n",
      "loss: 0.823799  [51200/60000]\n",
      "loss: 0.839144  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.673427 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.452047  [    0/60000]\n",
      "loss: 0.629293  [ 6400/60000]\n",
      "loss: 0.423565  [12800/60000]\n",
      "loss: 0.733085  [19200/60000]\n",
      "loss: 0.606067  [25600/60000]\n",
      "loss: 0.592635  [32000/60000]\n",
      "loss: 0.833507  [38400/60000]\n",
      "loss: 0.806633  [44800/60000]\n",
      "loss: 0.822164  [51200/60000]\n",
      "loss: 0.838419  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.672435 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.450458  [    0/60000]\n",
      "loss: 0.628012  [ 6400/60000]\n",
      "loss: 0.422891  [12800/60000]\n",
      "loss: 0.731733  [19200/60000]\n",
      "loss: 0.604290  [25600/60000]\n",
      "loss: 0.591198  [32000/60000]\n",
      "loss: 0.832342  [38400/60000]\n",
      "loss: 0.804739  [44800/60000]\n",
      "loss: 0.820561  [51200/60000]\n",
      "loss: 0.837772  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.671456 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.448927  [    0/60000]\n",
      "loss: 0.626681  [ 6400/60000]\n",
      "loss: 0.422240  [12800/60000]\n",
      "loss: 0.730338  [19200/60000]\n",
      "loss: 0.602547  [25600/60000]\n",
      "loss: 0.589874  [32000/60000]\n",
      "loss: 0.831160  [38400/60000]\n",
      "loss: 0.802914  [44800/60000]\n",
      "loss: 0.819001  [51200/60000]\n",
      "loss: 0.837182  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.670503 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.447447  [    0/60000]\n",
      "loss: 0.625368  [ 6400/60000]\n",
      "loss: 0.421669  [12800/60000]\n",
      "loss: 0.728906  [19200/60000]\n",
      "loss: 0.600900  [25600/60000]\n",
      "loss: 0.588500  [32000/60000]\n",
      "loss: 0.829826  [38400/60000]\n",
      "loss: 0.801114  [44800/60000]\n",
      "loss: 0.817439  [51200/60000]\n",
      "loss: 0.836654  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.669564 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.445954  [    0/60000]\n",
      "loss: 0.624072  [ 6400/60000]\n",
      "loss: 0.421054  [12800/60000]\n",
      "loss: 0.727505  [19200/60000]\n",
      "loss: 0.599324  [25600/60000]\n",
      "loss: 0.587163  [32000/60000]\n",
      "loss: 0.828638  [38400/60000]\n",
      "loss: 0.799282  [44800/60000]\n",
      "loss: 0.815851  [51200/60000]\n",
      "loss: 0.836102  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.668635 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.444534  [    0/60000]\n",
      "loss: 0.622818  [ 6400/60000]\n",
      "loss: 0.420439  [12800/60000]\n",
      "loss: 0.726158  [19200/60000]\n",
      "loss: 0.597862  [25600/60000]\n",
      "loss: 0.585869  [32000/60000]\n",
      "loss: 0.827439  [38400/60000]\n",
      "loss: 0.797494  [44800/60000]\n",
      "loss: 0.814267  [51200/60000]\n",
      "loss: 0.835462  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.667721 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.443194  [    0/60000]\n",
      "loss: 0.621556  [ 6400/60000]\n",
      "loss: 0.419829  [12800/60000]\n",
      "loss: 0.724744  [19200/60000]\n",
      "loss: 0.596441  [25600/60000]\n",
      "loss: 0.584620  [32000/60000]\n",
      "loss: 0.826271  [38400/60000]\n",
      "loss: 0.795809  [44800/60000]\n",
      "loss: 0.812664  [51200/60000]\n",
      "loss: 0.835121  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.666818 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.441897  [    0/60000]\n",
      "loss: 0.620334  [ 6400/60000]\n",
      "loss: 0.419205  [12800/60000]\n",
      "loss: 0.723379  [19200/60000]\n",
      "loss: 0.594931  [25600/60000]\n",
      "loss: 0.583377  [32000/60000]\n",
      "loss: 0.825046  [38400/60000]\n",
      "loss: 0.794157  [44800/60000]\n",
      "loss: 0.810987  [51200/60000]\n",
      "loss: 0.834553  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.665938 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.440641  [    0/60000]\n",
      "loss: 0.619197  [ 6400/60000]\n",
      "loss: 0.418625  [12800/60000]\n",
      "loss: 0.722024  [19200/60000]\n",
      "loss: 0.593472  [25600/60000]\n",
      "loss: 0.582171  [32000/60000]\n",
      "loss: 0.823816  [38400/60000]\n",
      "loss: 0.792538  [44800/60000]\n",
      "loss: 0.809360  [51200/60000]\n",
      "loss: 0.834069  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.665070 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.439440  [    0/60000]\n",
      "loss: 0.618046  [ 6400/60000]\n",
      "loss: 0.418051  [12800/60000]\n",
      "loss: 0.720690  [19200/60000]\n",
      "loss: 0.592014  [25600/60000]\n",
      "loss: 0.580990  [32000/60000]\n",
      "loss: 0.822610  [38400/60000]\n",
      "loss: 0.791018  [44800/60000]\n",
      "loss: 0.807552  [51200/60000]\n",
      "loss: 0.833495  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.664212 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.438237  [    0/60000]\n",
      "loss: 0.616889  [ 6400/60000]\n",
      "loss: 0.417534  [12800/60000]\n",
      "loss: 0.719319  [19200/60000]\n",
      "loss: 0.590577  [25600/60000]\n",
      "loss: 0.579811  [32000/60000]\n",
      "loss: 0.821382  [38400/60000]\n",
      "loss: 0.789433  [44800/60000]\n",
      "loss: 0.805786  [51200/60000]\n",
      "loss: 0.832905  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.663370 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.437080  [    0/60000]\n",
      "loss: 0.615709  [ 6400/60000]\n",
      "loss: 0.417068  [12800/60000]\n",
      "loss: 0.718041  [19200/60000]\n",
      "loss: 0.589157  [25600/60000]\n",
      "loss: 0.578599  [32000/60000]\n",
      "loss: 0.820205  [38400/60000]\n",
      "loss: 0.787943  [44800/60000]\n",
      "loss: 0.804046  [51200/60000]\n",
      "loss: 0.832352  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.662538 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.435922  [    0/60000]\n",
      "loss: 0.614537  [ 6400/60000]\n",
      "loss: 0.416584  [12800/60000]\n",
      "loss: 0.716804  [19200/60000]\n",
      "loss: 0.587781  [25600/60000]\n",
      "loss: 0.577359  [32000/60000]\n",
      "loss: 0.818997  [38400/60000]\n",
      "loss: 0.786387  [44800/60000]\n",
      "loss: 0.802181  [51200/60000]\n",
      "loss: 0.831836  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.661713 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.434840  [    0/60000]\n",
      "loss: 0.613256  [ 6400/60000]\n",
      "loss: 0.416093  [12800/60000]\n",
      "loss: 0.715642  [19200/60000]\n",
      "loss: 0.586364  [25600/60000]\n",
      "loss: 0.576114  [32000/60000]\n",
      "loss: 0.817814  [38400/60000]\n",
      "loss: 0.784883  [44800/60000]\n",
      "loss: 0.800345  [51200/60000]\n",
      "loss: 0.831569  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.660893 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.433748  [    0/60000]\n",
      "loss: 0.612107  [ 6400/60000]\n",
      "loss: 0.415597  [12800/60000]\n",
      "loss: 0.714319  [19200/60000]\n",
      "loss: 0.584991  [25600/60000]\n",
      "loss: 0.574897  [32000/60000]\n",
      "loss: 0.816664  [38400/60000]\n",
      "loss: 0.783318  [44800/60000]\n",
      "loss: 0.798663  [51200/60000]\n",
      "loss: 0.831102  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.660085 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.432666  [    0/60000]\n",
      "loss: 0.610875  [ 6400/60000]\n",
      "loss: 0.415143  [12800/60000]\n",
      "loss: 0.713003  [19200/60000]\n",
      "loss: 0.583749  [25600/60000]\n",
      "loss: 0.573645  [32000/60000]\n",
      "loss: 0.815548  [38400/60000]\n",
      "loss: 0.781755  [44800/60000]\n",
      "loss: 0.796944  [51200/60000]\n",
      "loss: 0.830750  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.659290 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.431593  [    0/60000]\n",
      "loss: 0.609787  [ 6400/60000]\n",
      "loss: 0.414666  [12800/60000]\n",
      "loss: 0.711722  [19200/60000]\n",
      "loss: 0.582420  [25600/60000]\n",
      "loss: 0.572405  [32000/60000]\n",
      "loss: 0.814453  [38400/60000]\n",
      "loss: 0.780270  [44800/60000]\n",
      "loss: 0.795306  [51200/60000]\n",
      "loss: 0.830404  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.658503 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.430598  [    0/60000]\n",
      "loss: 0.608688  [ 6400/60000]\n",
      "loss: 0.414201  [12800/60000]\n",
      "loss: 0.710368  [19200/60000]\n",
      "loss: 0.581154  [25600/60000]\n",
      "loss: 0.571190  [32000/60000]\n",
      "loss: 0.813342  [38400/60000]\n",
      "loss: 0.778794  [44800/60000]\n",
      "loss: 0.793702  [51200/60000]\n",
      "loss: 0.830051  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.657728 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.429616  [    0/60000]\n",
      "loss: 0.607641  [ 6400/60000]\n",
      "loss: 0.413754  [12800/60000]\n",
      "loss: 0.709061  [19200/60000]\n",
      "loss: 0.579839  [25600/60000]\n",
      "loss: 0.569964  [32000/60000]\n",
      "loss: 0.812263  [38400/60000]\n",
      "loss: 0.777353  [44800/60000]\n",
      "loss: 0.792349  [51200/60000]\n",
      "loss: 0.829728  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.656951 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.428620  [    0/60000]\n",
      "loss: 0.606480  [ 6400/60000]\n",
      "loss: 0.413336  [12800/60000]\n",
      "loss: 0.707775  [19200/60000]\n",
      "loss: 0.578600  [25600/60000]\n",
      "loss: 0.568799  [32000/60000]\n",
      "loss: 0.811133  [38400/60000]\n",
      "loss: 0.775868  [44800/60000]\n",
      "loss: 0.790720  [51200/60000]\n",
      "loss: 0.829458  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.656185 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.427624  [    0/60000]\n",
      "loss: 0.605324  [ 6400/60000]\n",
      "loss: 0.412905  [12800/60000]\n",
      "loss: 0.706496  [19200/60000]\n",
      "loss: 0.577394  [25600/60000]\n",
      "loss: 0.567626  [32000/60000]\n",
      "loss: 0.809991  [38400/60000]\n",
      "loss: 0.774380  [44800/60000]\n",
      "loss: 0.789216  [51200/60000]\n",
      "loss: 0.829117  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.655438 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.426707  [    0/60000]\n",
      "loss: 0.604196  [ 6400/60000]\n",
      "loss: 0.412506  [12800/60000]\n",
      "loss: 0.705209  [19200/60000]\n",
      "loss: 0.576167  [25600/60000]\n",
      "loss: 0.566533  [32000/60000]\n",
      "loss: 0.808800  [38400/60000]\n",
      "loss: 0.772932  [44800/60000]\n",
      "loss: 0.787658  [51200/60000]\n",
      "loss: 0.828746  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.654695 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.425814  [    0/60000]\n",
      "loss: 0.603157  [ 6400/60000]\n",
      "loss: 0.412127  [12800/60000]\n",
      "loss: 0.703942  [19200/60000]\n",
      "loss: 0.575011  [25600/60000]\n",
      "loss: 0.565415  [32000/60000]\n",
      "loss: 0.807685  [38400/60000]\n",
      "loss: 0.771546  [44800/60000]\n",
      "loss: 0.786065  [51200/60000]\n",
      "loss: 0.828410  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.653953 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.424971  [    0/60000]\n",
      "loss: 0.602086  [ 6400/60000]\n",
      "loss: 0.411766  [12800/60000]\n",
      "loss: 0.702749  [19200/60000]\n",
      "loss: 0.573790  [25600/60000]\n",
      "loss: 0.564328  [32000/60000]\n",
      "loss: 0.806547  [38400/60000]\n",
      "loss: 0.770168  [44800/60000]\n",
      "loss: 0.784569  [51200/60000]\n",
      "loss: 0.828087  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.653216 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.424140  [    0/60000]\n",
      "loss: 0.601063  [ 6400/60000]\n",
      "loss: 0.411387  [12800/60000]\n",
      "loss: 0.701569  [19200/60000]\n",
      "loss: 0.572651  [25600/60000]\n",
      "loss: 0.563233  [32000/60000]\n",
      "loss: 0.805456  [38400/60000]\n",
      "loss: 0.768732  [44800/60000]\n",
      "loss: 0.783038  [51200/60000]\n",
      "loss: 0.827727  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.652491 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.423368  [    0/60000]\n",
      "loss: 0.600019  [ 6400/60000]\n",
      "loss: 0.411066  [12800/60000]\n",
      "loss: 0.700389  [19200/60000]\n",
      "loss: 0.571834  [25600/60000]\n",
      "loss: 0.562178  [32000/60000]\n",
      "loss: 0.804322  [38400/60000]\n",
      "loss: 0.767342  [44800/60000]\n",
      "loss: 0.781533  [51200/60000]\n",
      "loss: 0.827418  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.651771 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.422581  [    0/60000]\n",
      "loss: 0.599002  [ 6400/60000]\n",
      "loss: 0.410657  [12800/60000]\n",
      "loss: 0.699237  [19200/60000]\n",
      "loss: 0.570763  [25600/60000]\n",
      "loss: 0.561109  [32000/60000]\n",
      "loss: 0.803148  [38400/60000]\n",
      "loss: 0.765975  [44800/60000]\n",
      "loss: 0.780094  [51200/60000]\n",
      "loss: 0.827053  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.651075 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.421986  [    0/60000]\n",
      "loss: 0.598064  [ 6400/60000]\n",
      "loss: 0.410313  [12800/60000]\n",
      "loss: 0.698005  [19200/60000]\n",
      "loss: 0.569679  [25600/60000]\n",
      "loss: 0.560067  [32000/60000]\n",
      "loss: 0.802060  [38400/60000]\n",
      "loss: 0.764519  [44800/60000]\n",
      "loss: 0.778642  [51200/60000]\n",
      "loss: 0.826704  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.650366 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.421251  [    0/60000]\n",
      "loss: 0.597030  [ 6400/60000]\n",
      "loss: 0.409985  [12800/60000]\n",
      "loss: 0.696758  [19200/60000]\n",
      "loss: 0.568668  [25600/60000]\n",
      "loss: 0.559044  [32000/60000]\n",
      "loss: 0.800943  [38400/60000]\n",
      "loss: 0.763102  [44800/60000]\n",
      "loss: 0.777152  [51200/60000]\n",
      "loss: 0.826413  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.649662 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.420533  [    0/60000]\n",
      "loss: 0.595992  [ 6400/60000]\n",
      "loss: 0.409606  [12800/60000]\n",
      "loss: 0.695547  [19200/60000]\n",
      "loss: 0.567598  [25600/60000]\n",
      "loss: 0.558024  [32000/60000]\n",
      "loss: 0.799872  [38400/60000]\n",
      "loss: 0.761735  [44800/60000]\n",
      "loss: 0.775686  [51200/60000]\n",
      "loss: 0.826117  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.648963 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.419817  [    0/60000]\n",
      "loss: 0.594931  [ 6400/60000]\n",
      "loss: 0.409251  [12800/60000]\n",
      "loss: 0.694290  [19200/60000]\n",
      "loss: 0.566548  [25600/60000]\n",
      "loss: 0.556990  [32000/60000]\n",
      "loss: 0.798786  [38400/60000]\n",
      "loss: 0.760346  [44800/60000]\n",
      "loss: 0.774188  [51200/60000]\n",
      "loss: 0.825849  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.648274 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.419149  [    0/60000]\n",
      "loss: 0.593831  [ 6400/60000]\n",
      "loss: 0.408884  [12800/60000]\n",
      "loss: 0.693073  [19200/60000]\n",
      "loss: 0.565495  [25600/60000]\n",
      "loss: 0.555970  [32000/60000]\n",
      "loss: 0.797681  [38400/60000]\n",
      "loss: 0.758998  [44800/60000]\n",
      "loss: 0.772728  [51200/60000]\n",
      "loss: 0.825543  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.647588 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.418511  [    0/60000]\n",
      "loss: 0.592768  [ 6400/60000]\n",
      "loss: 0.408492  [12800/60000]\n",
      "loss: 0.691870  [19200/60000]\n",
      "loss: 0.564489  [25600/60000]\n",
      "loss: 0.554933  [32000/60000]\n",
      "loss: 0.796608  [38400/60000]\n",
      "loss: 0.757686  [44800/60000]\n",
      "loss: 0.771160  [51200/60000]\n",
      "loss: 0.825256  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.646915 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.417912  [    0/60000]\n",
      "loss: 0.591819  [ 6400/60000]\n",
      "loss: 0.408092  [12800/60000]\n",
      "loss: 0.690651  [19200/60000]\n",
      "loss: 0.563588  [25600/60000]\n",
      "loss: 0.553883  [32000/60000]\n",
      "loss: 0.795423  [38400/60000]\n",
      "loss: 0.756351  [44800/60000]\n",
      "loss: 0.769640  [51200/60000]\n",
      "loss: 0.824932  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.646243 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.417301  [    0/60000]\n",
      "loss: 0.590778  [ 6400/60000]\n",
      "loss: 0.407694  [12800/60000]\n",
      "loss: 0.689442  [19200/60000]\n",
      "loss: 0.562658  [25600/60000]\n",
      "loss: 0.552811  [32000/60000]\n",
      "loss: 0.794312  [38400/60000]\n",
      "loss: 0.755074  [44800/60000]\n",
      "loss: 0.768114  [51200/60000]\n",
      "loss: 0.824670  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.645577 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.416694  [    0/60000]\n",
      "loss: 0.589788  [ 6400/60000]\n",
      "loss: 0.407241  [12800/60000]\n",
      "loss: 0.688253  [19200/60000]\n",
      "loss: 0.561785  [25600/60000]\n",
      "loss: 0.551752  [32000/60000]\n",
      "loss: 0.793186  [38400/60000]\n",
      "loss: 0.753819  [44800/60000]\n",
      "loss: 0.766634  [51200/60000]\n",
      "loss: 0.824375  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.644910 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.416170  [    0/60000]\n",
      "loss: 0.588858  [ 6400/60000]\n",
      "loss: 0.406775  [12800/60000]\n",
      "loss: 0.687006  [19200/60000]\n",
      "loss: 0.560844  [25600/60000]\n",
      "loss: 0.550663  [32000/60000]\n",
      "loss: 0.792137  [38400/60000]\n",
      "loss: 0.752632  [44800/60000]\n",
      "loss: 0.765186  [51200/60000]\n",
      "loss: 0.824018  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.644249 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.415703  [    0/60000]\n",
      "loss: 0.587964  [ 6400/60000]\n",
      "loss: 0.406368  [12800/60000]\n",
      "loss: 0.685829  [19200/60000]\n",
      "loss: 0.559989  [25600/60000]\n",
      "loss: 0.549673  [32000/60000]\n",
      "loss: 0.791082  [38400/60000]\n",
      "loss: 0.751429  [44800/60000]\n",
      "loss: 0.763635  [51200/60000]\n",
      "loss: 0.823811  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.643590 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.415203  [    0/60000]\n",
      "loss: 0.586990  [ 6400/60000]\n",
      "loss: 0.405998  [12800/60000]\n",
      "loss: 0.684652  [19200/60000]\n",
      "loss: 0.559139  [25600/60000]\n",
      "loss: 0.548735  [32000/60000]\n",
      "loss: 0.789981  [38400/60000]\n",
      "loss: 0.750128  [44800/60000]\n",
      "loss: 0.762149  [51200/60000]\n",
      "loss: 0.823545  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.642942 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.414691  [    0/60000]\n",
      "loss: 0.585911  [ 6400/60000]\n",
      "loss: 0.405634  [12800/60000]\n",
      "loss: 0.683515  [19200/60000]\n",
      "loss: 0.558326  [25600/60000]\n",
      "loss: 0.547776  [32000/60000]\n",
      "loss: 0.788927  [38400/60000]\n",
      "loss: 0.748836  [44800/60000]\n",
      "loss: 0.760458  [51200/60000]\n",
      "loss: 0.823065  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.642292 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.414188  [    0/60000]\n",
      "loss: 0.584950  [ 6400/60000]\n",
      "loss: 0.405246  [12800/60000]\n",
      "loss: 0.682336  [19200/60000]\n",
      "loss: 0.557560  [25600/60000]\n",
      "loss: 0.546873  [32000/60000]\n",
      "loss: 0.787775  [38400/60000]\n",
      "loss: 0.747545  [44800/60000]\n",
      "loss: 0.759006  [51200/60000]\n",
      "loss: 0.822686  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.641649 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.413664  [    0/60000]\n",
      "loss: 0.584038  [ 6400/60000]\n",
      "loss: 0.404937  [12800/60000]\n",
      "loss: 0.681157  [19200/60000]\n",
      "loss: 0.556770  [25600/60000]\n",
      "loss: 0.545925  [32000/60000]\n",
      "loss: 0.786662  [38400/60000]\n",
      "loss: 0.746313  [44800/60000]\n",
      "loss: 0.757647  [51200/60000]\n",
      "loss: 0.822340  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.641017 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.413250  [    0/60000]\n",
      "loss: 0.583162  [ 6400/60000]\n",
      "loss: 0.404578  [12800/60000]\n",
      "loss: 0.679964  [19200/60000]\n",
      "loss: 0.555953  [25600/60000]\n",
      "loss: 0.545037  [32000/60000]\n",
      "loss: 0.785524  [38400/60000]\n",
      "loss: 0.745036  [44800/60000]\n",
      "loss: 0.756205  [51200/60000]\n",
      "loss: 0.821936  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.640383 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.412829  [    0/60000]\n",
      "loss: 0.582275  [ 6400/60000]\n",
      "loss: 0.404205  [12800/60000]\n",
      "loss: 0.678826  [19200/60000]\n",
      "loss: 0.555199  [25600/60000]\n",
      "loss: 0.544128  [32000/60000]\n",
      "loss: 0.784448  [38400/60000]\n",
      "loss: 0.743780  [44800/60000]\n",
      "loss: 0.754795  [51200/60000]\n",
      "loss: 0.821516  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.639760 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.412390  [    0/60000]\n",
      "loss: 0.581435  [ 6400/60000]\n",
      "loss: 0.403864  [12800/60000]\n",
      "loss: 0.677721  [19200/60000]\n",
      "loss: 0.554347  [25600/60000]\n",
      "loss: 0.543195  [32000/60000]\n",
      "loss: 0.783376  [38400/60000]\n",
      "loss: 0.742487  [44800/60000]\n",
      "loss: 0.753460  [51200/60000]\n",
      "loss: 0.821153  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.639147 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.411949  [    0/60000]\n",
      "loss: 0.580588  [ 6400/60000]\n",
      "loss: 0.403524  [12800/60000]\n",
      "loss: 0.676690  [19200/60000]\n",
      "loss: 0.553489  [25600/60000]\n",
      "loss: 0.542263  [32000/60000]\n",
      "loss: 0.782306  [38400/60000]\n",
      "loss: 0.741092  [44800/60000]\n",
      "loss: 0.752034  [51200/60000]\n",
      "loss: 0.820744  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.638538 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.411512  [    0/60000]\n",
      "loss: 0.579756  [ 6400/60000]\n",
      "loss: 0.403200  [12800/60000]\n",
      "loss: 0.675587  [19200/60000]\n",
      "loss: 0.552821  [25600/60000]\n",
      "loss: 0.541301  [32000/60000]\n",
      "loss: 0.781250  [38400/60000]\n",
      "loss: 0.739720  [44800/60000]\n",
      "loss: 0.750631  [51200/60000]\n",
      "loss: 0.820422  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.637934 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.411091  [    0/60000]\n",
      "loss: 0.578933  [ 6400/60000]\n",
      "loss: 0.402873  [12800/60000]\n",
      "loss: 0.674475  [19200/60000]\n",
      "loss: 0.552043  [25600/60000]\n",
      "loss: 0.540407  [32000/60000]\n",
      "loss: 0.780197  [38400/60000]\n",
      "loss: 0.738491  [44800/60000]\n",
      "loss: 0.749358  [51200/60000]\n",
      "loss: 0.820124  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.637343 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")\n",
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}